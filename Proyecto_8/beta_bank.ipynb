{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo para Beta Bank"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice <a id='back'></a>\n",
    "* [Introducción](#intro)\n",
    "* [Etapa 1. Descripción de los datos](#data_review)\n",
    "    * [1. 1. Valores Ausentes](#data_review_missing)\n",
    "    * [1. 2. Codificación de datos categóricos](#data_review_categoric)\n",
    "    * [1. 3. Conclusiones](#data_review_conclusions)\n",
    "* [Etapa 2. Segmentación de los datos](#data_segmentation)\n",
    "    * [2. 1. Estandarización de datos numéricos](#data_segmentation_standard)\n",
    "* [Etapa 3. Elección del mejor modelo](#data_model)\n",
    "    * [3.1. El mejor modelo con desequilibrio de clases](#data_model_imbalance)\n",
    "    * [3.2. Ajuste de peso de clase](#data_model_weight)\n",
    "    * [3.3. Sobremuestreo](#data_model_upsampling)\n",
    "    * [3.4. Conclusiones](#data_model_conclusions)\n",
    "* [Etapa 4. Prueba final](#data_test)\n",
    "* [Etapa 5. Conclusiones](#data_conclusion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción <a id='intro'></a>\n",
    "\n",
    "Beta Bank está perdiendo clientes cada mes, poco a poco. El banco descubrió que es más barato salvar a los clientes existentes que atraer nuevos. Se cuenta con los datos sobre el comportamiento de los clientes y su terminación de contrato con el banco.\n",
    "\n",
    "**Objetivo**\n",
    "\n",
    "El objetivo de este proyecto es crear un modelo con el máximo valor *F1* posible. Este valor debe ser mayor o igual que 0.59.\n",
    "\n",
    "**Etapas**\n",
    "Los datos se almacenan en el archivo `/datasets/Churn.csv`. Como se desconoce la calidad de los datos, el proyecto consistirá en cinco etapas:\n",
    "\n",
    "1. Descripción y preprocesamiento de los datos.\n",
    "2. Segmentación de los datos.\n",
    "3. Elección del mejor modelo.\n",
    "4. Prueba final.\n",
    "5. Conclusión general.\n",
    "\n",
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1. Descripción de los datos <a id='data_review'></a>\n",
    "\n",
    "Se importan las librerías necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score, roc_auc_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee el archivo y se guardará en la variable `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('Churn.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se imprimirá la información general de `df` y las primeras 10 filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age   \n",
      "0          1    15634602  Hargrave          619    France  Female   42  \\\n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "5          6    15574012       Chu          645     Spain    Male   44   \n",
      "6          7    15592531  Bartlett          822    France    Male   50   \n",
      "7          8    15656148    Obinna          376   Germany  Female   29   \n",
      "8          9    15792365        He          501    France    Male   44   \n",
      "9         10    15592389        H?          684    France    Male   27   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember   \n",
      "0     2.0       0.00              1          1               1  \\\n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "5     8.0  113755.78              2          1               0   \n",
      "6     7.0       0.00              2          1               1   \n",
      "7     4.0  115046.74              4          1               0   \n",
      "8     4.0  142051.07              2          0               1   \n",
      "9     2.0  134603.88              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "5        149756.71       1  \n",
      "6         10062.80       0  \n",
      "7        119346.88       1  \n",
      "8         74940.50       0  \n",
      "9         71725.73       0  \n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "print(df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset cuenta con 10,000 filas, cada una de las cuales contiene información del comportamiento sobre un cliente. Las 13 columnas de características son:\n",
    "\n",
    "1. `'RowNumber'` - índice de cadena de datos.\n",
    "2. `'CustomerId'` - Identificador único de cliente.\n",
    "3. `'Surname'` - apellido del cliente.\n",
    "4. `'CreditScore'` - valor de crédito del cliente.\n",
    "5. `'Geography'` - País de residencia.\n",
    "6. `'Gender'` - sexo.\n",
    "7. `'Age'` - edad.\n",
    "8. `'Tenure'` - período durante el cual ha madurado el depósito a plazo fijo del cliente (en años).\n",
    "9. `'Balance'` - saldo de la cuenta.\n",
    "10. `'NumOfProducts'` - número de productos bancarios utilizados por el cliente.\n",
    "11. `'HasCrCard'` - el cliente tiene una tarjeta de crédito (1 - si, 0 - no).\n",
    "12. `'IsActiveMember'` - el cliente es mimbro (1 - si, 0 - no).\n",
    "13. `'EstimatedSalary'` - salario estimado.\n",
    "\n",
    "La columna objetivo `'Exited'` la cual contiene información sobre si el cliente se ha ido (1 - si, 0 - no).\n",
    "\n",
    "Observamos que los nombres de las columnas no están de la manera usual (minúsculas y usando `_` para separar palabras), se procederá a cambiarlos. La columna `'Tenure'` tiene valores ausentes, se investigarán más adelante para tratarlos. Gracias al identificador único de cliente es sencillo comprobar si existen duplicados obvios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
      "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
      "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Nombres de las columnas del dataframe\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_number', 'customer_id', 'surname', 'credit_score', 'geography',\n",
      "       'gender', 'age', 'tenure', 'balance', 'num_of_products', 'has_cr_card',\n",
      "       'is_active_member', 'estimated_salary', 'exited'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df.columns = ['row_number', 'customer_id', 'surname', 'credit_score', 'geography',\n",
    "       'gender', 'age', 'tenure', 'balance', 'num_of_products', 'has_cr_card',\n",
    "       'is_active_member', 'estimated_salary', 'exited']\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que los nombres de las columnas está actualizados, se comprobará si existen duplicados obvios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No existen duplicados obvios. En la siguiente sección se tratarán los valores ausentes.\n",
    "\n",
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 1. Valores ausentes <a id='data_review_missing'></a>\n",
    "\n",
    "Se imprimirán las primeras 10 filas con valores ausentes para investigar más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     row_number  customer_id    surname  credit_score geography  gender  age   \n",
      "30           31     15589475    Azikiwe           591     Spain  Female   39  \\\n",
      "48           49     15766205        Yin           550   Germany    Male   38   \n",
      "51           52     15768193  Trevisani           585   Germany    Male   36   \n",
      "53           54     15702298   Parkhill           655   Germany    Male   41   \n",
      "60           61     15651280     Hunter           742   Germany    Male   35   \n",
      "82           83     15641732      Mills           543    France  Female   36   \n",
      "85           86     15805254    Ndukaku           652     Spain  Female   75   \n",
      "94           95     15676966      Capon           730     Spain    Male   42   \n",
      "99          100     15633059    Fanucci           413    France    Male   34   \n",
      "111         112     15665790   Rowntree           538   Germany    Male   39   \n",
      "\n",
      "     tenure    balance  num_of_products  has_cr_card  is_active_member   \n",
      "30      NaN       0.00                3            1                 0  \\\n",
      "48      NaN  103391.38                1            0                 1   \n",
      "51      NaN  146050.97                2            0                 0   \n",
      "53      NaN  125561.97                1            0                 0   \n",
      "60      NaN  136857.00                1            0                 0   \n",
      "82      NaN       0.00                2            0                 0   \n",
      "85      NaN       0.00                2            1                 1   \n",
      "94      NaN       0.00                2            0                 1   \n",
      "99      NaN       0.00                2            0                 0   \n",
      "111     NaN  108055.10                2            1                 0   \n",
      "\n",
      "     estimated_salary  exited  \n",
      "30          140469.38       1  \n",
      "48           90878.13       0  \n",
      "51           86424.57       0  \n",
      "53          164040.94       1  \n",
      "60           84509.57       0  \n",
      "82           26019.59       0  \n",
      "85          114675.75       0  \n",
      "94           85982.47       0  \n",
      "99            6534.18       0  \n",
      "111          27231.26       0  \n"
     ]
    }
   ],
   "source": [
    "print(df[df['tenure'].isna()].head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No parece existir ninguna relación con la información de otra columna. Se imprimiran las estadísticas de esta columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    9091.000000\n",
      "mean        4.997690\n",
      "std         2.894723\n",
      "min         0.000000\n",
      "25%         2.000000\n",
      "50%         5.000000\n",
      "75%         7.000000\n",
      "max        10.000000\n",
      "Name: tenure, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['tenure'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.09\n"
     ]
    }
   ],
   "source": [
    "#porcentaje de valores ausentes\n",
    "print(len(df[df['tenure'].isna()]) / len(df) * 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es el 9% de los datos, se decide reemplazar los valores ausentes por la mediana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_number          0\n",
      "customer_id         0\n",
      "surname             0\n",
      "credit_score        0\n",
      "geography           0\n",
      "gender              0\n",
      "age                 0\n",
      "tenure              0\n",
      "balance             0\n",
      "num_of_products     0\n",
      "has_cr_card         0\n",
      "is_active_member    0\n",
      "estimated_salary    0\n",
      "exited              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "median = df['tenure'].median()\n",
    "df = df.fillna(median)\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya no existen valores ausentes. En la siguiente sección se preparán los datos para el modelo.\n",
    "\n",
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 2. Codificación de datos categóricos<a id='data_review_categoric'></a>\n",
    "\n",
    "Existen columnas que no aportarán información relevante al modelo, las cuales son:\n",
    "\n",
    "* `'row_number'` - esta columna describe casi la misma información que el índice del dataframe, la diferencia es que comienza en 1. No es una característica para el modelo.\n",
    "* `'customer_id'` - esta información identifica al cliente de manera única lo cual no es relevante para el modelo.\n",
    "* `'surname'` - el apellido del cliente es otra manera de identificar lo cual tampoco es relevante para el modelo.\n",
    "\n",
    "Se procede a eliminar estas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   credit_score geography  gender  age  tenure    balance  num_of_products   \n",
      "0           619    France  Female   42     2.0       0.00                1  \\\n",
      "1           608     Spain  Female   41     1.0   83807.86                1   \n",
      "2           502    France  Female   42     8.0  159660.80                3   \n",
      "3           699    France  Female   39     1.0       0.00                2   \n",
      "4           850     Spain  Female   43     2.0  125510.82                1   \n",
      "\n",
      "   has_cr_card  is_active_member  estimated_salary  exited  \n",
      "0            1                 1         101348.88       1  \n",
      "1            0                 1         112542.58       0  \n",
      "2            1                 0         113931.57       1  \n",
      "3            0                 0          93826.63       0  \n",
      "4            1                 1          79084.10       0  \n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['row_number', 'customer_id', 'surname'], axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se codificarán las columnas categóricas, sólo son dos `'geography'` y `'gender'`. Para ello se imprimirá la cantidad de valores en ambas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geography\n",
      "France     5014\n",
      "Germany    2509\n",
      "Spain      2477\n",
      "Name: count, dtype: int64\n",
      "gender\n",
      "Male      5457\n",
      "Female    4543\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['geography'].value_counts())\n",
    "print(df['gender'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la columna `'geography'` se tienen tres opciones, mientras que en la columna `'gender'` se tienen dos. Al codificarlas aparecerán tres columnas para la primera y dos para la segunda. Sin embargo, se puede reducir eliminando la primera de cada una. Esto es, se tendrán las columnas `'geography_France'`, `'geography_Germnay'` y `'geography_Spain'`, en donde será 1 en el país de residencia y 0 en otro caso. Se observa que si el cliente reside en Francia entonces en las otras dos columnas aparecerá 0, por ello quitar la primera columna mantiene la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   credit_score  age  tenure    balance  num_of_products  has_cr_card   \n",
      "0           619   42     2.0       0.00                1            1  \\\n",
      "1           608   41     1.0   83807.86                1            0   \n",
      "2           502   42     8.0  159660.80                3            1   \n",
      "3           699   39     1.0       0.00                2            0   \n",
      "4           850   43     2.0  125510.82                1            1   \n",
      "\n",
      "   is_active_member  estimated_salary  exited  geography_Germany   \n",
      "0                 1         101348.88       1                  0  \\\n",
      "1                 1         112542.58       0                  0   \n",
      "2                 0         113931.57       1                  0   \n",
      "3                 0          93826.63       0                  0   \n",
      "4                 1          79084.10       0                  0   \n",
      "\n",
      "   geography_Spain  gender_Male  \n",
      "0                0            0  \n",
      "1                1            0  \n",
      "2                0            0  \n",
      "3                0            0  \n",
      "4                1            0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df, drop_first=True, dtype=int)\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 3. Conclusiones <a id='data_review_conclusions'></a>\n",
    "\n",
    "En esta etapa se describieron las columnas que contiene el dataframe. No se encontraron duplicados obvios y la única columna con valores ausentes fue `'tenure'`. Se reemplazaron estos valores con la mediana.\n",
    "\n",
    "También se codificaron los datos de tipo categórico, estos fueron los correspondientes a las columnas con la información del país de residencia y el género de cada cliente.\n",
    "\n",
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2. Segmentación de los datos <a id='data_segmentation'></a>\n",
    "\n",
    "En esta etapa se segmentará el dataset `df` en tres conjuntos, siguiendo una proporción 3:1:1. Es decir, se tendrán lo siguiente:\n",
    "\n",
    "1. un conjunto de entrenamiento que representa el 60% de los datos,\n",
    "2. un conjunto de validación que representa el 20% y\n",
    "3. un conjunto de prueba que representa el 20% restante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero se segmenta df para obtener el conjunto de entrenamiento (60%)\n",
    "df_train, df2 = train_test_split(df, test_size=0.40, random_state=12345)\n",
    "# Ahora se segmenta el resto (df2) a la mitad para obtener los conjuntos de validación y de prueba, cada uno con el 20% de df\n",
    "df_valid, df_test = train_test_split(df2, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de entrenamiento es `df_train`, el de validación es `df_valid` y el de prueba es `df_test`.\n",
    "\n",
    "Se filtrarán los datasets para establecer las características y el objetivo del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = df_train.drop(['exited'], axis=1)\n",
    "target_train = df_train['exited']\n",
    "features_valid = df_valid.drop(['exited'], axis=1)\n",
    "target_valid = df_valid['exited']\n",
    "features_test = df_test.drop(['exited'], axis=1)\n",
    "target_test = df_test['exited']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 1. Estandarización de datos numéricos <a id='data_segmentation_standard'></a>\n",
    "\n",
    "A continuación se estandarizarán los datos numéricos en el conjunto de entrenamiento, posteriormente se utilizarán estos parámetros para estandarizar los datos numéricos de los conjuntos de validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['credit_score', 'age', 'tenure', 'balance',\n",
    "           'num_of_products', 'estimated_salary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente etapa se buscará el mejor modelo.\n",
    "\n",
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 3. Elección del mejor modelo <a id='data_model'></a>\n",
    "\n",
    "Primero se investigará el equilibrio de clases. Para ello se imprimirán los valores de `target_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exited\n",
      "0    4804\n",
      "1    1196\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(target_train.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El porcentaje de clientes que no se han ido es aproximadamente del 80%, es quiere decir que se tiene una proporción de 4:1. Las clases están desequilibradas.\n",
    "\n",
    "Se buscará el mejor modelo, primero sin tomar en cuenta el desequilibrio de las clases y en caso de no superar el 0.59 en el valor F1, entonces se ajustará este desequilibrio."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 1. El mejor modelo con desequilibrio de clases <a id='data_model_imbalance'></a>\n",
    "\n",
    "El primer modelo se creará con un árbol de decisión y se ajustará la profundidad máxima para obtener el valor F1 más alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1, F1: 0.0, AUC-ROC: 0.693\n",
      "max_depth = 2, F1: 0.522, AUC-ROC: 0.75\n",
      "max_depth = 3, F1: 0.423, AUC-ROC: 0.797\n",
      "max_depth = 4, F1: 0.553, AUC-ROC: 0.813\n",
      "max_depth = 5, F1: 0.541, AUC-ROC: 0.823\n",
      "max_depth = 6, F1: 0.569, AUC-ROC: 0.816\n",
      "max_depth = 7, F1: 0.538, AUC-ROC: 0.815\n",
      "max_depth = 8, F1: 0.543, AUC-ROC: 0.81\n",
      "max_depth = 9, F1: 0.562, AUC-ROC: 0.781\n",
      "max_depth = 10, F1: 0.537, AUC-ROC: 0.767\n",
      "max_depth = 11, F1: 0.52, AUC-ROC: 0.735\n",
      "max_depth = 12, F1: 0.518, AUC-ROC: 0.709\n",
      "max_depth = 13, F1: 0.505, AUC-ROC: 0.691\n",
      "max_depth = 14, F1: 0.501, AUC-ROC: 0.688\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 15):\n",
    "    model = DecisionTreeClassifier(random_state=54321, max_depth=i)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    f1 = round(f1_score(target_valid, predictions), 3)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = round(roc_auc_score(target_valid, probabilities_one_valid), 3)\n",
    "    print(f'max_depth = {i}, F1: {f1}, AUC-ROC: {auc_roc}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor F1 mayor es con profundidad máxima 6, el cual es igual a 0.569 con un valor AUC-ROC igual a 0.816. Este valor F1 no supera 0.59.\n",
    "\n",
    "Se probará con un modelo creado con un bosque aleatorio. Se ajustará tanto la profundidad como el número de árboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (n_estimators = 10, max_depth = 9): 0.5984962406015036\n"
     ]
    }
   ],
   "source": [
    "best_F1 = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "for i in range(1, 11): #rango de profundidad\n",
    "    for est in range(10, 101, 10): # rango para los ábroles, comenzando en 10, terminando en 100 y dando saltos de 10 en 10\n",
    "        model = RandomForestClassifier(random_state=54321, max_depth=i, n_estimators=est) # n_estimators ajusta el número de árboles\n",
    "        model.fit(features_train, target_train)\n",
    "        predictions = model.predict(features_valid)\n",
    "        f1 = f1_score(target_valid, predictions)\n",
    "        if f1 > best_F1:\n",
    "            best_F1 = f1\n",
    "            best_est = est\n",
    "            best_depth = i            \n",
    "\n",
    "print(\"F1 del mejor modelo en el conjunto de validación (n_estimators = {}, max_depth = {}): {}\".format(best_est, best_depth, best_F1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo es con 10 árboles y profundidad máxima igual a 9. Se calculará el valor AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.5984962406015036, AUC-ROC = 0.8389431946721188\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=54321, max_depth=9, n_estimators=10)\n",
    "rf_model.fit(features_train, target_train)\n",
    "rf_predictions = rf_model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, rf_predictions)\n",
    "rf_probabilities_valid = rf_model.predict_proba(features_valid)\n",
    "rf_probabilities_one_valid = rf_probabilities_valid[:, 1]\n",
    "rf_auc_roc = roc_auc_score(target_valid, rf_probabilities_one_valid)\n",
    "\n",
    "print(f'F1 = {f1}, AUC-ROC = {rf_auc_roc}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, el valor F1 cumple con lo esperado (es mayor o igual que 0.59) y el valor AUC-ROC es cercano a 1.\n",
    "\n",
    "A continuación, se examinará un modelo creado con regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.33108108108108103, AUC-ROC = 0.7587512627102753\n"
     ]
    }
   ],
   "source": [
    "rl_model = LogisticRegression(random_state=54321, solver='liblinear')\n",
    "rl_model.fit(features_train, target_train)\n",
    "rl_predictions = rl_model.predict(features_valid)\n",
    "rl_f1 = f1_score(target_valid, rl_predictions)\n",
    "rl_probabilities_valid = rl_model.predict_proba(features_valid)\n",
    "rl_probabilities_one_valid = rl_probabilities_valid[:, 1]\n",
    "rl_auc_roc = roc_auc_score(target_valid, rl_probabilities_one_valid)\n",
    "\n",
    "print(f'F1 = {rl_f1}, AUC-ROC = {rl_auc_roc}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este modelo el valor F1 decayó a 0.33, también el valor AUC-ROC decayó a 0.75. Se decide que el mejor modelo es el creado con el algoritmo de bosque aleatorio. Se tomará este modelo para ajustar el desequilibrio de clases en la siguiente sección.\n",
    "\n",
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 2. Ajuste de peso de clase <a id='data_model_weight'></a>\n",
    "\n",
    "Se tiene que la clase rara es el 1, entonces se equilibrarán los pesos de clase balanceándolos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.6077097505668935, AUC-ROC = 0.8410194835439362\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=54321, max_depth=9, n_estimators=10, class_weight='balanced')\n",
    "rf_model.fit(features_train, target_train)\n",
    "rf_predictions = rf_model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, rf_predictions)\n",
    "rf_probabilities_valid = rf_model.predict_proba(features_valid)\n",
    "rf_probabilities_one_valid = rf_probabilities_valid[:, 1]\n",
    "rf_auc_roc = roc_auc_score(target_valid, rf_probabilities_one_valid)\n",
    "\n",
    "print(f'F1 = {f1}, AUC-ROC = {rf_auc_roc}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa, el valor F1 aumentó a 0.60, así como el valor AUC-ROC aumentó a 0.84. En la siguiente sección se utilizará el enfoque de sobremuestreo para equilibrar las clases.\n",
    "\n",
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 3. Sobremuestreo <a id='data_model_upsampling'></a>\n",
    "\n",
    "En esta sección se utilizará la técnica del sobremuestreo para verificar si se obtiene un mejor modelo que en la sección anterior. Primero se creará una función que realice todo el procedimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=54321\n",
    "    )\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizará esta función para averiguar el mayor valor F1 posible cuando se varía `repeat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat = 1, F1=0.5813253012048193\n",
      "Repeat = 2, F1=0.6062992125984252\n",
      "Repeat = 3, F1=0.6109175377468061\n",
      "Repeat = 4, F1=0.601472134595163\n",
      "Repeat = 5, F1=0.6011673151750972\n",
      "Repeat = 6, F1=0.5696316262353999\n",
      "Repeat = 7, F1=0.5542372881355931\n",
      "Repeat = 8, F1=0.5516102394715111\n",
      "Repeat = 9, F1=0.5373831775700935\n",
      "Repeat = 10, F1=0.5210332103321033\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, i\n",
    "    )\n",
    "    ups_model = RandomForestClassifier(random_state=54321, max_depth=9, n_estimators=10)\n",
    "    ups_model.fit(features_upsampled, target_upsampled)\n",
    "    ups_predictions = ups_model.predict(features_valid)\n",
    "    ups_f1 = f1_score(target_valid, ups_predictions)\n",
    "    print(f'Repeat = {i}, F1={ups_f1}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mayor valor F1 es con 3, aumenta a 0.61. Se calculará el valor AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.6109175377468061, AUC-ROC = 0.8375655550783636\n"
     ]
    }
   ],
   "source": [
    "ups_model = RandomForestClassifier(random_state=54321, max_depth=9, n_estimators=10)\n",
    "ups_model.fit(features_upsampled, target_upsampled)\n",
    "ups_predictions = ups_model.predict(features_valid)\n",
    "ups_f1 = f1_score(target_valid, ups_predictions)\n",
    "ups_probabilities_valid = ups_model.predict_proba(features_valid)\n",
    "ups_probabilities_one_valid = ups_probabilities_valid[:, 1]\n",
    "ups_auc_roc = roc_auc_score(target_valid, ups_probabilities_one_valid)\n",
    "\n",
    "print(f'F1 = {ups_f1}, AUC-ROC = {ups_auc_roc}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En comparación con la técnica de ajuste de peso, el valor AUC-ROC bajó, sin sembargo la diferencia es mínima. Se decide usar este modelo como el mejor.\n",
    "\n",
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 4. Conclusiones <a id='data_model_conclusions'></a>\n",
    "\n",
    "En esta estapa se encontró que el mejor algortimo para entrenar el modelo es el bosque aleatorio con 10 árboles y profundidad máxima igual a 9. Esto se hizo sin tomar en cuenta el desequilibrio de clases.\n",
    "\n",
    "Posteriormente se contempló este desequilibrio y para mejorar la calidad del modelo se compararon dos técnicas de equilibrio. La primera fue el ajuste de peso de clase y la segunda el sobremuestro. Esta última técnica arrojó un valor F1 mayor, por lo que se decide usar este modelo para el conjunto de dato de prueba.\n",
    "\n",
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 4. Prueba final <a id='data_test'></a>\n",
    "\n",
    "En esta etapa se hará la prueba final del modelo elegido con el conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.5934314835787089, AUC-ROC = 0.8411316036823665\n"
     ]
    }
   ],
   "source": [
    "test_predictions = ups_model.predict(features_test)\n",
    "test_f1 = f1_score(target_test, test_predictions)\n",
    "test_probabilities_valid = ups_model.predict_proba(features_test)\n",
    "test_probabilities_one_valid = test_probabilities_valid[:, 1]\n",
    "test_auc_roc = roc_auc_score(target_test, test_probabilities_one_valid)\n",
    "\n",
    "print(f'F1 = {test_f1}, AUC-ROC = {test_auc_roc}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor F1 bajó a 0.59, sin embargo sigue siendo mayor o igual a lo esperado. El modelo es aceptable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 5. Conclusión general <a id='data_conclusion'></a>\n",
    "\n",
    "El conjunto de datos se dividió en tres partes: conjunto de entrenamiento (60%), conjunto de validación (20%) y conjunto de prueba (20%). Con los datos del conjunto de entrenamiento se crearon y entrenaron los modelos, usando los tres tipos de algoritmos de clasificación: árbol de decisión, bosque aleatorio y regresión lógistica, sin tomar en cuenta el desequilibrio de clases.\n",
    "\n",
    "Para elegir el mejor modelo se ajustaron hiperparámetros y se comprobó el valor F1 de cada uno de los modelos con los datos del conjunto de validación. En el árbol de decisión se concluyó que el mayor valor F1 se obtuvó con profundidad máxima igual a 6, mientras que para el bosque aleatorio, se alcanzó el mayor valor F1 con 10 árboles y profundidad máxima igual a 9.\n",
    "\n",
    "Comparando el valor F1 de los tres algoritmos, se concluyó que el mejor modelo es el bosque aleatorio (10 árboles y produndidad máxima 9).\n",
    "\n",
    "Posterior a esto, se equilibraron las clases, comparando dos técnicas resultando mejor el sobremuestreo. Finalmente, se comprobó la calidad del modelo con los datos del conjunto de prueba, obteniendo un valor F1 igual a 0.59, diferencia mínima con respecto al valor F1 en el conjunto de validación. Esta cantidad concluye que el modelo cumple el objetivo.\n",
    "\n",
    "[Volver a Contenidos](#back)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
